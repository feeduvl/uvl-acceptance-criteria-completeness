package de.uhd.ifi.se.accompleteness.extractor.vn;

import de.uhd.ifi.se.acgen.exception.NoUserStoryException;
import de.uhd.ifi.se.acgen.exception.TokenNotFoundException;
import de.uhd.ifi.se.accompleteness.extractor.USExtractor;
import de.uhd.ifi.se.accompleteness.extractor.openie.util.ActionUtils;
import de.uhd.ifi.se.acgen.generator.gherkin.util.PreprocessingUtils;
import de.uhd.ifi.se.acgen.generator.gherkin.util.SharedUtils;
import de.uhd.ifi.se.acgen.generator.gherkin.util.UIPreconditionUtils;
import de.uhd.ifi.se.acgen.model.UserStory;
import edu.stanford.nlp.ling.CoreAnnotations;
import edu.stanford.nlp.ling.IndexedWord;
import edu.stanford.nlp.pipeline.Annotation;
import edu.stanford.nlp.pipeline.CoreSentence;
import edu.stanford.nlp.pipeline.StanfordCoreNLP;
import edu.stanford.nlp.semgraph.SemanticGraph;
import edu.stanford.nlp.semgraph.SemanticGraphEdge;
import edu.stanford.nlp.semgraph.SemanticGraphCoreAnnotations.EnhancedPlusPlusDependenciesAnnotation;
import edu.stanford.nlp.util.CoreMap;

import java.util.ArrayList;
import java.util.Arrays;
import java.util.List;
import java.util.Properties;
import java.util.Set;

import de.uhd.ifi.se.accompleteness.model.NLPResultSingle;
import de.uhd.ifi.se.accompleteness.model.Relationship;
import de.uhd.ifi.se.accompleteness.model.Topic;

public class VNUSExtractor implements USExtractor {
        /**
     * {@inheritDoc}
     * 
     * The acceptance criteria generated by this method follow Gherkin syntax, 
     * i.e.: “GIVEN [precondition] WHEN [action] THEN [expected results]”.
     * 
     * @see Generator
     */
    public NLPResultSingle extract(UserStory userStory, boolean debug, boolean filterUSTopics) throws TokenNotFoundException {
        String userStoryString = userStory.getUserStoryString();

        List<Topic> topics = new ArrayList<Topic>();
        List<Relationship> relationships = new ArrayList<>();

        // Preprocess the user story string
        userStoryString = preprocessing(userStoryString);
        UserStory newUserStory = null;
        
        try {
            newUserStory = new UserStory(userStoryString);
        } catch (NoUserStoryException e) {
            e.printStackTrace();
        }
        // Set up the NLP pipeline and annotate the preprocessed user story
        // string
        Properties props = new Properties();
        props.setProperty("annotators", "tokenize,ssplit,pos,lemma,depparse,natlog,openie");
        StanfordCoreNLP pipeline = new StanfordCoreNLP(props);
        Annotation document = new Annotation(userStoryString);
        Annotation document_goal = new Annotation(newUserStory.getGoal());
        Annotation document_reason = new Annotation(newUserStory.getReason());
        pipeline.annotate(document);
        pipeline.annotate(document_goal);
        pipeline.annotate(document_reason);
        
        CoreMap sentence = document_goal.get(CoreAnnotations.SentencesAnnotation.class).get(0);

        SemanticGraph graph =
                    sentence.get(EnhancedPlusPlusDependenciesAnnotation.class);

        IndexedWord main_verb = null;
        IndexedWord subject = null;
        IndexedWord main_object = null;
        // Simple case if the subj and dobj are linked by a verb
        for (SemanticGraphEdge edge: graph.edgeIterable()) {
        }
        for (SemanticGraphEdge edge : graph.edgeIterable()) {
            if (edge.getRelation().getShortName().startsWith("nsubj")) {
                subject = edge.getDependent();
                if (edge.getSource().tag().startsWith("VB") && !( edge.getSource().originalText().equals("can")) && !( edge.getSource().originalText().equals("want"))) {
                    main_verb = edge.getSource();
                    break;
                }
            }
        }

        for (SemanticGraphEdge edge : graph.edgeIterable()) {
            if (edge.getRelation().getShortName().startsWith("obj")) {
                main_object = edge.getTarget();
                break;
                // if (edge.getSource().tag().equals("PRON")) {
                //     for (Relationship relationship : relationships) {
                        
                //     }
                // }
            }
        }

        topics.add(new Topic(main_object.lemma()));
        relationships.add(new Relationship(new Topic(subject.lemma()), new Topic(main_object.lemma()), main_verb.lemma()));

        return new NLPResultSingle(relationships, topics);
    }

    /**
     * Preprocesses the user story, i.e., convert the user story to third
     * person.
     * 
     * @param userStoryString a string containing the user story
     * @return a string containing the preprocessed user story
     * @throws TokenNotFoundException if an essential part of a user story such
     * as the verb or the subject could not be identified by the Stanford
     * CoreNLP tools.
     * 
     * @see GherkinGenerator#generate
     * @see PreprocessingUtils
     */
    private String preprocessing(String userStoryString) throws TokenNotFoundException {
        return userStoryString.replaceAll("[^a-zA-Z ]", "");
    }

    /**
     * Extracts information regarding the role of a user story and creates an
     * acceptance criterion from it.
     * 
     * @param sentence a {@code CoreSentence} containing the NLP analysis
     * result of the user story
     * @param userStoryString a string containing the user story
     * @return a list containing zero or one acceptance criteria with
     * information regarding the role of the user story
     * 
     * @see GherkinGenerator#generate
     */
    private List<Topic> extractRolePrecondition(CoreSentence sentence, String userStoryString) {
        List<Topic> topics = new ArrayList<Topic>();

        // all words in the sentence
        Set<IndexedWord> wordsInUserStorySentence = sentence.dependencyParse().getSubgraphVertices(sentence.dependencyParse().getFirstRoot());
        
        // Identify the “As a” and “I want” parts of the user story, where the
        // “I want” part should be “the user wants” by now, and find the
        // 1-based indices of both keywords.
        int indexAs = Integer.MAX_VALUE;
        int indexTheUserWants = 0;
        for (IndexedWord word : wordsInUserStorySentence) {
            if (word.word().equalsIgnoreCase("as") && word.tag().equals("IN")) {
                // Also check whether “as” is a preposition and…
                indexAs = Math.min(indexAs, word.index());
            } else if (word.word().equalsIgnoreCase("the") && word.tag().equals("DT")) {
                // …“the” is a determiner, just to make sure we found the right
                // words

                // after the determiner “the”, we expect the words “user”, a
                // singular noun (NN), and “wants”, a third-person singular
                // present verb (VBZ)
                IndexedWord expectedUser = sentence.dependencyParse().getNodeByIndex(word.index() + 1);
                IndexedWord expectedWants = sentence.dependencyParse().getNodeByIndex(word.index() + 2);
                if (expectedUser.word().equalsIgnoreCase("user") && expectedUser.tag().equals("NN") && expectedWants.word().equalsIgnoreCase("wants") && expectedWants.tag().equals("VBZ")) {
                    indexTheUserWants = Math.max(indexTheUserWants, word.index());

                    // Since the “the user wants” must occur after the “As a”,
                    // we can stop here
                    break;
                }
            }
        }

        // If both parts were identified, we determine the 1-based indices
        // of the first word after “As a” and the last word before the “the
        // user wants”, which should correspond to the role specification
        // in the user story, and then retrieve the begin and end position
        // of these words in the user story string.
        int beginPosition = sentence.dependencyParse().getNodeByIndex(indexAs + 1).beginPosition();
        int endPosition = sentence.dependencyParse().getNodeByIndex(indexTheUserWants - 1).endPosition();

        // If the role specification ends with a comma (e.g. “As a
        // developer, the user wants…”), we exclude it.
        //          ^
        if (sentence.dependencyParse().getNodeByIndex(indexTheUserWants - 1).tag().equals(",")) {
            endPosition = sentence.dependencyParse().getNodeByIndex(indexTheUserWants - 1 - 1).endPosition();
        }
        topics.add(new Topic(userStoryString.substring(beginPosition, endPosition)));

        return topics;
    }

    /**
     * Extracts information regarding the user interface of a user story and
     * creates an acceptance criterion from it.
     * 
     * @param sentence a {@code CoreSentence} containing the NLP analysis
     * result of the user story
     * @param userStoryString a string containing the user story
     * @return a list containing zero or one acceptance criteria with
     * information regarding the user interface of the user story
     * 
     * @see GherkinGenerator#generate
     * @see UIPreconditionUtils
     */
    private List<Topic> extractUIPrecondition(CoreSentence sentence, String userStoryString) {
        List<Topic> topics = new ArrayList<Topic>();
        List<String> nerTags = sentence.nerTags(); // the named entity recognizer tags
        List<String> posTags = sentence.posTags(); // the POS tags
        List<String> tokensAsStrings = sentence.tokensAsStrings(); // the words of the user story
        int beginIndex = Integer.MAX_VALUE;

        // If a user interface description is found by the Named Entity
        // Recognizer, the words being part of that description are tagged with
        // “UI”.

        // for every word in the sentence
        for (int i = 0; i < nerTags.size() - 1; i++) {
            if (nerTags.get(i).equals("UI")) {
                // We found a UI description and continue with it
                beginIndex = i;
                break;
            }
            if (tokensAsStrings.get(i).equalsIgnoreCase("so") && tokensAsStrings.get(i + 1).equalsIgnoreCase("that")) {
                // We have reached the reason part of the user story and will
                // not find any useful UI description there, so we return the
                // empty list
                return topics;
            }
        }

        if (beginIndex == Integer.MAX_VALUE) {
            // We have not found a UI description in the entire user story, so
            // we return the empty list
            return topics;
        }

        // We now need to find the end of the user interface description.
        int endIndex = UIPreconditionUtils.getEndIndexOfUI(beginIndex, sentence);
        if (posTags.get(endIndex).equals(",") || posTags.get(endIndex).equals("HYPH")) {
            // If the UI description ends with a comma or a hyphen, we remove
            // this last token
            endIndex -= 1;
        }

        // If both parts were identified, we determine the 1-based indices of
        // the first and last UI description words and then retrieve the begin
        // and end position of these words in the user story string. However,
        // we make sure that the first word of the UI description is “the”
        // (which is always required to be part of a UI description by the NER
        // regex) and not “displayed”, which may also occur.
        int beginPosition = sentence.dependencyParse().getNodeByIndex(beginIndex + 1).beginPosition();
        beginPosition = userStoryString.indexOf("the", beginPosition);
        int endPosition = sentence.dependencyParse().getNodeByIndex(endIndex + 1).endPosition();
        topics.add(new Topic(userStoryString.substring(beginPosition, endPosition)));

        return topics;
    }

    /**
     * Extracts actions from a user story and creates acceptance criteria from
     * it.
     * 
     * @param sentence a {@code CoreSentence} containing the NLP analysis
     * result of the user story
     * @param userStoryString a string containing the user story
     * @return a list containing zero or more acceptance criteria with
     * actions from the user story
     * 
     * @see GherkinGenerator#generate
     * @see ActionUtils
     */
    private List<Topic> extractActions(CoreSentence sentence, String userStoryString) {
        List<Topic> topics = new ArrayList<Topic>();
        List<String> tokensAsStrings = sentence.tokensAsStrings();

        // Find the 1-based index of the “so that” keyword of the user story
        // or the 1-based index of the last word, if there is no reason in the
        // user story.
        int indexSoThat = tokensAsStrings.size() + 1;
        for (int i = 1; i < tokensAsStrings.size(); i++) {
            if (tokensAsStrings.get(i - 1).equalsIgnoreCase("so") && tokensAsStrings.get(i).equalsIgnoreCase("that")) {
                indexSoThat = i;
                break;
            }
        }

        // These words weaken a conditional sentence. For example, if a user
        // story goes “I want B to happen if A occurs”, A is the only known
        // cause for the effect B. However, if the user story goes “I want B to
        // happen even if A occurs”, there appear to be many other causes for
        // B. We are not interested in those conditions.
        List<String> conditionalLimiterStrings = Arrays.asList("also", "even", "especially", "necessary");

        List<IndexedWord> conditionalStarterWords = new ArrayList<IndexedWord>();

        // Look for conditional starter words (declared above) in the words of
        // the user story that are before the user story reason.
        for (int i = 3; i < indexSoThat; i++) {
            IndexedWord word = sentence.dependencyParse().getNodeByIndex(i);
            if ((SharedUtils.conditionalStarterStrings.contains(word.word().toLowerCase()) || ActionUtils.isAsSoonAs(sentence, i)) && !conditionalLimiterStrings.contains(sentence.dependencyParse().getNodeByIndex(i - 1).word().toLowerCase()) && !sentence.dependencyParse().getNodeByIndex(i + 1).word().equalsIgnoreCase("and")) {
                // If the current word is either a conditional starter word or
                // the AS in an “as soon AS” and the previous word is not a
                // conditional limiter word and the following word is not “and”
                // (to exclude structures like “I want to know when AND from
                // which IP adress …”), we have found a conditional sentence.
                conditionalStarterWords.add(sentence.dependencyParse().getNodeByIndex(i));
            }
        }

        if (indexSoThat + 2 < tokensAsStrings.size() && SharedUtils.conditionalStarterStrings.contains(sentence.dependencyParse().getNodeByIndex(indexSoThat + 2).word().toLowerCase())) {
            // If the word following “so that” is a conditional starter word,
            // the reason of the user story is an example containing a
            // conditional sentence which we can use (e.g. “…, so that if A
            // occurs, B happens.”).
            conditionalStarterWords.add(sentence.dependencyParse().getNodeByIndex(indexSoThat + 2));
        }

        // Extract an action from every conditional starter word
        for (IndexedWord conditionalStarterWord : conditionalStarterWords) {
            topics.addAll(ActionUtils.extractActionFromConditionalStarterWord(sentence, userStoryString, conditionalStarterWord, indexSoThat));
        }

        // Also look for interactions in the user story, as in “I want to click
        // A in order to reach B”, and extract actions from them.
        topics.addAll(ActionUtils.extractActionFromInteraction(sentence, userStoryString));

        return topics;
    }

    // /**
    //  * Extracts the expected result from a user story and creates an acceptance
    //  * criterion from it. This acceptance criterion consists of all information
    //  * from the goal part of the user story except for the information that is
    //  * already included in other acceptance criteria
    //  * 
    //  * @param sentence a {@code CoreSentence} containing the NLP analysis
    //  * result of the user story
    //  * @param userStoryString a string containing the user story
    //  * @param acceptanceCriteria all acceptance criteria extracted so far,
    //  * i.e., role and UI preconditions, actions and expected results from the
    //  * reason of the user story
    //  * @return a list containing one acceptance criterion with the expected
    //  * result of the user story
    //  * @throws TokenNotFoundException if the verb of the user story could not
    //  * be identified by the Stanford CoreNLP tools during postprocessing.
    //  * 
    //  * @see GherkinGenerator#generate
    //  * @see ResultUtils
    //  */
    // private List<AcceptanceCriterion> extractResults(CoreSentence sentence, String userStoryString, List<AcceptanceCriterion> acceptanceCriteria) throws TokenNotFoundException {
    //     String resultString = userStoryString;

    //     // Cut off the result string at the reason part of the user story
    //     int indexSoThat = userStoryString.toUpperCase().indexOf("SO THAT");
    //     if (indexSoThat != -1) {
    //         resultString = resultString.substring(0, indexSoThat);
    //     }

    //     // Remove commas, sentence periods and spaces at the end of the result
    //     // string
    //     while (resultString.endsWith(",") || resultString.endsWith(" ") || resultString.endsWith(".")) {
    //         resultString = resultString.substring(0, resultString.length() - 1);
    //     }

    //     // Iterate over all acceptance criteria
    //     for (AcceptanceCriterion acceptanceCriterion : acceptanceCriteria) {
    //         if (acceptanceCriterion.getBeginReplacementIndex() <= 0 || acceptanceCriterion.getEndReplacementIndex() > sentence.tokensAsStrings().size() || acceptanceCriterion.getBeginReplacementIndex() >= acceptanceCriterion.getEndReplacementIndex() || acceptanceCriterion.getType().equals(AcceptanceCriterionType.UI)) {
    //             // Acceptance criteria are skipped if they hold no valid
    //             // 1-based replacement indices (<= 0 or larger than the number
    //             // of words in the sentence or end index is larger than the
    //             // begin index) or if they contain UI information which is
    //             // handled separately.
    //             continue;
    //         }

    //         // We retrieve the begin and end position of the words to be
    //         // replaced in the user story string. 
    //         int beginReplacementPosition = sentence.dependencyParse().getNodeByIndex(acceptanceCriterion.getBeginReplacementIndex()).beginPosition();
    //         int endReplacementPosition = sentence.dependencyParse().getNodeByIndex(acceptanceCriterion.getEndReplacementIndex()).endPosition();
    //         if (beginReplacementPosition > resultString.length()) {
    //             // if the replacement would take place in the reason of the
    //             // user story which was already cut off, we can safely ignore it
    //             continue;
    //         }

    //         // Replace all characters between the begin and end position with
    //         // whitespaces, thereby retaining all other character positions for
    //         // future replacements.
    //         resultString = resultString.substring(0, beginReplacementPosition) + " ".repeat(endReplacementPosition - beginReplacementPosition) + resultString.substring(endReplacementPosition);
    //     }

    //     // Call postprocessing method before creating and returning exactly one
    //     // acceptance criterion.
    //     return Arrays.asList(new AcceptanceCriterion(ResultUtils.postprocessResultString(resultString, sentence), AcceptanceCriterionType.RESULT));
    // }
}
