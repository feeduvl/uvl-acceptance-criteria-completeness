package de.uhd.ifi.se.acgen.generator.gherkin;

import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collections;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Properties;
import java.util.Set;

import de.uhd.ifi.se.acgen.exception.TokenNotFoundException;
import de.uhd.ifi.se.acgen.generator.Generator;
import de.uhd.ifi.se.acgen.generator.gherkin.util.*;
import de.uhd.ifi.se.acgen.model.AcceptanceCriterion;
import de.uhd.ifi.se.acgen.model.AcceptanceCriterionType;
import de.uhd.ifi.se.acgen.model.UserStory;
import edu.stanford.nlp.ling.IndexedWord;
import edu.stanford.nlp.pipeline.CoreDocument;
import edu.stanford.nlp.pipeline.CoreSentence;
import edu.stanford.nlp.pipeline.StanfordCoreNLP;

/**
 * Generates acceptance criteria for a user story. The acceptance criteria 
 * generated by this generator follow Gherkin syntax, i.e.: “GIVEN
 * [precondition] WHEN [action] THEN [expected results]”.
 * 
 * @see Generator
 */
public class GherkinGenerator implements Generator {

    /**
     * {@inheritDoc}
     * 
     * The acceptance criteria generated by this method follow Gherkin syntax, 
     * i.e.: “GIVEN [precondition] WHEN [action] THEN [expected results]”.
     * 
     * @see Generator
     */
    public List<AcceptanceCriterion> generate(UserStory userStory, boolean debug) throws TokenNotFoundException {
        String userStoryString = userStory.getUserStoryString();
        List<AcceptanceCriterion> acceptanceCriteria = new ArrayList<AcceptanceCriterion>();

        // Preprocess the user story string
        userStoryString = preprocessing(userStoryString);
        if (debug) {
            // If debug information have been requested, the preprocessed user
            // story string is added as a debug message.
            acceptanceCriteria.add(new AcceptanceCriterion(userStoryString, AcceptanceCriterionType.DEBUG));
        }

        // Set up the NLP pipeline and annotate the preprocessed user story
        // string
        Properties props = new Properties();
        props.setProperty("annotators", "tokenize,ssplit,pos,lemma,ner,depparse,regexner");
        props.setProperty("ssplit.isOneSentence", "true");
        props.setProperty("regexner.mapping", "src/main/java/de/uhd/ifi/se/acgen/generator/gherkin/regexner/ui-mapping.txt");
        StanfordCoreNLP pipeline = new StanfordCoreNLP(props);
        CoreDocument document = new CoreDocument(userStoryString);
        pipeline.annotate(document);
        CoreSentence userStorySentence = document.sentences().get(0);

        // Generate acceptance criteria of various types
        acceptanceCriteria.addAll(extractRolePrecondition(userStorySentence, userStoryString));
        acceptanceCriteria.addAll(extractUIPrecondition(userStorySentence, userStoryString));
        acceptanceCriteria.addAll(extractActions(userStorySentence, userStoryString));
        acceptanceCriteria.addAll(extractResults(userStorySentence, userStoryString, acceptanceCriteria));

        // Sort acceptance criteria so that WHEN – THEN relations are
        // represented correctly
        Collections.sort(acceptanceCriteria);

        // Resolve duplicate information that occurs multiple times in
        // different acceptance criteria.
        acceptanceCriteria = resolveDuplicateInformation(acceptanceCriteria);

        return acceptanceCriteria;
    }

    /**
     * Preprocesses the user story, i.e., convert the user story to third
     * person.
     * 
     * @param userStoryString a string containing the user story
     * @return a string containing the preprocessed user story
     * @throws TokenNotFoundException if an essential part of a user story such
     * as the verb or the subject could not be identified by the Stanford
     * CoreNLP tools.
     * 
     * @see GherkinGenerator#generate
     * @see PreprocessingUtils
     */
    private String preprocessing(String userStoryString) throws TokenNotFoundException {
        // Set up the NLP pipeline and annotate the original user story string
        Properties props = new Properties();
        props.setProperty("annotators", "tokenize,ssplit,pos,lemma,ner,depparse,coref");
        props.setProperty("ssplit.isOneSentence", "true");
        StanfordCoreNLP pipeline = new StanfordCoreNLP(props);
        CoreDocument document = new CoreDocument(userStoryString);
        pipeline.annotate(document);
        CoreSentence userStorySentence = document.sentences().get(0);

        Map<Integer, String> replacements = new HashMap<Integer, String>();

        // Generate a map which shows where to replace which words by which
        // other words in order to convert the user story to third person.
        replacements.putAll(PreprocessingUtils.switchToThirdPerson(document, userStorySentence));

        // Return a string where the replacements determined before are
        // implemented.
        return PreprocessingUtils.replaceWordsInSentence(userStorySentence, userStoryString, replacements);
    }


    /**
     * Extracts information regarding the role of a user story and creates an
     * acceptance criterion from it.
     * 
     * @param sentence a {@code CoreSentence} containing the NLP analysis
     * result of the user story
     * @param userStoryString a string containing the user story
     * @return a list containing zero or one acceptance criteria with
     * information regarding the role of the user story
     * 
     * @see GherkinGenerator#generate
     */
    private List<AcceptanceCriterion> extractRolePrecondition(CoreSentence sentence, String userStoryString) {
        List<AcceptanceCriterion> acceptanceCriteria = new ArrayList<AcceptanceCriterion>();

        // all words in the sentence
        Set<IndexedWord> wordsInUserStorySentence = sentence.dependencyParse().getSubgraphVertices(sentence.dependencyParse().getFirstRoot());
        
        // Identify the “As a” and “I want” parts of the user story, where the
        // “I want” part should be “the user wants” by now, and find the
        // 1-based indices of both keywords.
        int indexAs = Integer.MAX_VALUE;
        int indexTheUserWants = 0;
        for (IndexedWord word : wordsInUserStorySentence) {
            if (word.word().equalsIgnoreCase("as") && word.tag().equals("IN")) {
                // Also check whether “as” is a preposition and…
                indexAs = Math.min(indexAs, word.index());
            } else if (word.word().equalsIgnoreCase("the") && word.tag().equals("DT")) {
                // …“the” is a determiner, just to make sure we found the right
                // words

                // after the determiner “the”, we expect the words “user”, a
                // singular noun (NN), and “wants”, a third-person singular
                // present verb (VBZ)
                IndexedWord expectedUser = sentence.dependencyParse().getNodeByIndex(word.index() + 1);
                IndexedWord expectedWants = sentence.dependencyParse().getNodeByIndex(word.index() + 2);
                if (expectedUser.word().equalsIgnoreCase("user") && expectedUser.tag().equals("NN") && expectedWants.word().equalsIgnoreCase("wants") && expectedWants.tag().equals("VBZ")) {
                    indexTheUserWants = Math.max(indexTheUserWants, word.index());

                    // Since the “the user wants” must occur after the “As a”,
                    // we can stop here
                    break;
                }
            }
        }

        // If both parts were identified, we determine the 1-based indices
        // of the first word after “As a” and the last word before the “the
        // user wants”, which should correspond to the role specification
        // in the user story, and then retrieve the begin and end position
        // of these words in the user story string.
        int beginPosition = sentence.dependencyParse().getNodeByIndex(indexAs + 1).beginPosition();
        int endPosition = sentence.dependencyParse().getNodeByIndex(indexTheUserWants - 1).endPosition();

        // If the role specification ends with a comma (e.g. “As a
        // developer, the user wants…”), we exclude it.
        //          ^
        if (sentence.dependencyParse().getNodeByIndex(indexTheUserWants - 1).tag().equals(",")) {
            endPosition = sentence.dependencyParse().getNodeByIndex(indexTheUserWants - 1 - 1).endPosition();
        }
        acceptanceCriteria.add(new AcceptanceCriterion(userStoryString.substring(beginPosition, endPosition), AcceptanceCriterionType.ROLE, indexAs, indexTheUserWants - 1));

        return acceptanceCriteria;
    }

    /**
     * Extracts information regarding the user interface of a user story and
     * creates an acceptance criterion from it.
     * 
     * @param sentence a {@code CoreSentence} containing the NLP analysis
     * result of the user story
     * @param userStoryString a string containing the user story
     * @return a list containing zero or one acceptance criteria with
     * information regarding the user interface of the user story
     * 
     * @see GherkinGenerator#generate
     * @see UIPreconditionUtils
     */
    private List<AcceptanceCriterion> extractUIPrecondition(CoreSentence sentence, String userStoryString) {
        List<AcceptanceCriterion> acceptanceCriteria = new ArrayList<AcceptanceCriterion>();
        List<String> nerTags = sentence.nerTags(); // the named entity recognizer tags
        List<String> posTags = sentence.posTags(); // the POS tags
        List<String> tokensAsStrings = sentence.tokensAsStrings(); // the words of the user story
        int beginIndex = Integer.MAX_VALUE;

        // If a user interface description is found by the Named Entity
        // Recognizer, the words being part of that description are tagged with
        // “UI”.

        // for every word in the sentence
        for (int i = 0; i < nerTags.size() - 1; i++) {
            if (nerTags.get(i).equals("UI")) {
                // We found a UI description and continue with it
                beginIndex = i;
                break;
            }
            if (tokensAsStrings.get(i).equalsIgnoreCase("so") && tokensAsStrings.get(i + 1).equalsIgnoreCase("that")) {
                // We have reached the reason part of the user story and will
                // not find any useful UI description there, so we return the
                // empty list
                return acceptanceCriteria;
            }
        }

        if (beginIndex == Integer.MAX_VALUE) {
            // We have not found a UI description in the entire user story, so
            // we return the empty list
            return acceptanceCriteria;
        }

        // We now need to find the end of the user interface description.
        int endIndex = UIPreconditionUtils.getEndIndexOfUI(beginIndex, sentence);
        if (posTags.get(endIndex).equals(",") || posTags.get(endIndex).equals("HYPH")) {
            // If the UI description ends with a comma or a hyphen, we remove
            // this last token
            endIndex -= 1;
        }

        // If both parts were identified, we determine the 1-based indices of
        // the first and last UI description words and then retrieve the begin
        // and end position of these words in the user story string. However,
        // we make sure that the first word of the UI description is “the”
        // (which is always required to be part of a UI description by the NER
        // regex) and not “displayed”, which may also occur.
        int beginPosition = sentence.dependencyParse().getNodeByIndex(beginIndex + 1).beginPosition();
        beginPosition = userStoryString.indexOf("the", beginPosition);
        int endPosition = sentence.dependencyParse().getNodeByIndex(endIndex + 1).endPosition();
        acceptanceCriteria.add(new AcceptanceCriterion(userStoryString.substring(beginPosition, endPosition), AcceptanceCriterionType.UI, beginIndex + 1, endIndex + 1));

        return acceptanceCriteria;
    }

    /**
     * Extracts actions from a user story and creates acceptance criteria from
     * it.
     * 
     * @param sentence a {@code CoreSentence} containing the NLP analysis
     * result of the user story
     * @param userStoryString a string containing the user story
     * @return a list containing zero or more acceptance criteria with
     * actions from the user story
     * 
     * @see GherkinGenerator#generate
     * @see ActionUtils
     */
    private List<AcceptanceCriterion> extractActions(CoreSentence sentence, String userStoryString) {
        List<AcceptanceCriterion> acceptanceCriteria = new ArrayList<AcceptanceCriterion>();
        List<String> tokensAsStrings = sentence.tokensAsStrings();

        // Find the 1-based index of the “so that” keyword of the user story
        // or the 1-based index of the last word, if there is no reason in the
        // user story.
        int indexSoThat = tokensAsStrings.size() + 1;
        for (int i = 1; i < tokensAsStrings.size(); i++) {
            if (tokensAsStrings.get(i - 1).equalsIgnoreCase("so") && tokensAsStrings.get(i).equalsIgnoreCase("that")) {
                indexSoThat = i;
                break;
            }
        }

        // These words weaken a conditional sentence. For example, if a user
        // story goes “I want B to happen if A occurs”, A is the only known
        // cause for the effect B. However, if the user story goes “I want B to
        // happen even if A occurs”, there appear to be many other causes for
        // B. We are not interested in those conditions.
        List<String> conditionalLimiterStrings = Arrays.asList("also", "even", "especially", "necessary");

        List<IndexedWord> conditionalStarterWords = new ArrayList<IndexedWord>();

        // Look for conditional starter words (declared above) in the words of
        // the user story that are before the user story reason.
        for (int i = 3; i < indexSoThat; i++) {
            IndexedWord word = sentence.dependencyParse().getNodeByIndex(i);
            if ((SharedUtils.conditionalStarterStrings.contains(word.word().toLowerCase()) || ActionUtils.isAsSoonAs(sentence, i)) && !conditionalLimiterStrings.contains(sentence.dependencyParse().getNodeByIndex(i - 1).word().toLowerCase()) && !sentence.dependencyParse().getNodeByIndex(i + 1).word().equalsIgnoreCase("and")) {
                // If the current word is either a conditional starter word or
                // the AS in an “as soon AS” and the previous word is not a
                // conditional limiter word and the following word is not “and”
                // (to exclude structures like “I want to know when AND from
                // which IP adress …”), we have found a conditional sentence.
                conditionalStarterWords.add(sentence.dependencyParse().getNodeByIndex(i));
            }
        }

        if (indexSoThat + 2 < tokensAsStrings.size() && SharedUtils.conditionalStarterStrings.contains(sentence.dependencyParse().getNodeByIndex(indexSoThat + 2).word().toLowerCase())) {
            // If the word following “so that” is a conditional starter word,
            // the reason of the user story is an example containing a
            // conditional sentence which we can use (e.g. “…, so that if A
            // occurs, B happens.”).
            conditionalStarterWords.add(sentence.dependencyParse().getNodeByIndex(indexSoThat + 2));
        }

        // Extract an action from every conditional starter word
        for (IndexedWord conditionalStarterWord : conditionalStarterWords) {
            acceptanceCriteria.addAll(ActionUtils.extractActionFromConditionalStarterWord(sentence, userStoryString, conditionalStarterWord, indexSoThat));
        }

        // Also look for interactions in the user story, as in “I want to click
        // A in order to reach B”, and extract actions from them.
        acceptanceCriteria.addAll(ActionUtils.extractActionFromInteraction(sentence, userStoryString));

        return acceptanceCriteria;
    }

    /**
     * Extracts the expected result from a user story and creates an acceptance
     * criterion from it. This acceptance criterion consists of all information
     * from the goal part of the user story except for the information that is
     * already included in other acceptance criteria
     * 
     * @param sentence a {@code CoreSentence} containing the NLP analysis
     * result of the user story
     * @param userStoryString a string containing the user story
     * @param acceptanceCriteria all acceptance criteria extracted so far,
     * i.e., role and UI preconditions, actions and expected results from the
     * reason of the user story
     * @return a list containing one acceptance criterion with the expected
     * result of the user story
     * @throws TokenNotFoundException if the verb of the user story could not
     * be identified by the Stanford CoreNLP tools during postprocessing.
     * 
     * @see GherkinGenerator#generate
     * @see ResultUtils
     */
    private List<AcceptanceCriterion> extractResults(CoreSentence sentence, String userStoryString, List<AcceptanceCriterion> acceptanceCriteria) throws TokenNotFoundException {
        String resultString = userStoryString;

        // Cut off the result string at the reason part of the user story
        int indexSoThat = userStoryString.toUpperCase().indexOf("SO THAT");
        if (indexSoThat != -1) {
            resultString = resultString.substring(0, indexSoThat);
        }

        // Remove commas, sentence periods and spaces at the end of the result
        // string
        while (resultString.endsWith(",") || resultString.endsWith(" ") || resultString.endsWith(".")) {
            resultString = resultString.substring(0, resultString.length() - 1);
        }

        // Iterate over all acceptance criteria
        for (AcceptanceCriterion acceptanceCriterion : acceptanceCriteria) {
            if (acceptanceCriterion.getBeginReplacementIndex() <= 0 || acceptanceCriterion.getEndReplacementIndex() > sentence.tokensAsStrings().size() || acceptanceCriterion.getBeginReplacementIndex() >= acceptanceCriterion.getEndReplacementIndex() || acceptanceCriterion.getType().equals(AcceptanceCriterionType.UI)) {
                // Acceptance criteria are skipped if they hold no valid
                // 1-based replacement indices (<= 0 or larger than the number
                // of words in the sentence or end index is larger than the
                // begin index) or if they contain UI information which is
                // handled separately.
                continue;
            }

            // We retrieve the begin and end position of the words to be
            // replaced in the user story string. 
            int beginReplacementPosition = sentence.dependencyParse().getNodeByIndex(acceptanceCriterion.getBeginReplacementIndex()).beginPosition();
            int endReplacementPosition = sentence.dependencyParse().getNodeByIndex(acceptanceCriterion.getEndReplacementIndex()).endPosition();
            if (beginReplacementPosition > resultString.length()) {
                // if the replacement would take place in the reason of the
                // user story which was already cut off, we can safely ignore it
                continue;
            }

            // Replace all characters between the begin and end position with
            // whitespaces, thereby retaining all other character positions for
            // future replacements.
            resultString = resultString.substring(0, beginReplacementPosition) + " ".repeat(endReplacementPosition - beginReplacementPosition) + resultString.substring(endReplacementPosition);
        }

        // Call postprocessing method before creating and returning exactly one
        // acceptance criterion.
        return Arrays.asList(new AcceptanceCriterion(ResultUtils.postprocessResultString(resultString, sentence), AcceptanceCriterionType.RESULT));
    }

    /**
     * Removes or replaces information from acceptance criteria that occurs
     * multiple times in different acceptance criteria.
     * 
     * @param acceptanceCriteria a list of acceptance criteria to be resolved
     * @return a list of acceptance criteria without duplicate information
     * 
     * @see GherkinGenerator#generate
     * @see PostprocessingUtils
     */
    private List<AcceptanceCriterion> resolveDuplicateInformation(List<AcceptanceCriterion> acceptanceCriteria) {
        List<AcceptanceCriterion> resolvedAcceptanceCriteria = new ArrayList<AcceptanceCriterion>();

        String uiDescription = null;

        for (int i = 0; i < acceptanceCriteria.size(); i++) {
            switch (acceptanceCriteria.get(i).getType()) {
                case UI:
                    // If the acceptance criterion is a UI precondition, we
                    // store the UI description string
                    uiDescription = acceptanceCriteria.get(i).getRawString();
                    resolvedAcceptanceCriteria.add(acceptanceCriteria.get(i));
                    break;

                case ACTION:
                    // If the acceptance criterion is an action, we check if
                    // there is another action acceptance criterion following
                    // it.
                    AcceptanceCriterion resolvedAcceptanceCriterion = acceptanceCriteria.get(i);
                    if (i + 1 < acceptanceCriteria.size() && acceptanceCriteria.get(i + 1).getType().equals(AcceptanceCriterionType.ACTION)) {
                        // Check whether the next action is contained in the
                        // current acceptance criterion, and cut the current
                        // acceptance criterion accordingly so that both
                        // acceptance criteria remain and no duplicate
                        // information exists.
                        resolvedAcceptanceCriterion = PostprocessingUtils.cutOffAtNextAcceptanceCriterion(resolvedAcceptanceCriterion, acceptanceCriteria.get(i + 1));
                    }
                    // Replace the UI description by a generic expression
                    resolvedAcceptanceCriteria.add(PostprocessingUtils.replaceUIDescription(resolvedAcceptanceCriterion, uiDescription));
                    break;

                case RESULT:
                    // Replace the UI description by a generic expression
                    resolvedAcceptanceCriteria.add(PostprocessingUtils.replaceUIDescription(acceptanceCriteria.get(i), uiDescription));
                    break;
            
                case ACTION_IN_REASON:
                    // Replace the UI description by a generic expression
                    resolvedAcceptanceCriteria.add(PostprocessingUtils.replaceUIDescription(acceptanceCriteria.get(i), uiDescription));
                    break;

                case RESULT_IN_REASON:
                    // Replace the UI description by a generic expression
                    resolvedAcceptanceCriteria.add(PostprocessingUtils.replaceUIDescription(acceptanceCriteria.get(i), uiDescription));
                    break;

                default:
                    // Add log messages as is.
                    resolvedAcceptanceCriteria.add(acceptanceCriteria.get(i));
                    break;
            }
        }

        return resolvedAcceptanceCriteria;
    }

}
